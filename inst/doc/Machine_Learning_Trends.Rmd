Machine Learning Trends in Pubmed
========================================================


This is how I have been looking at machine learning trends in pubmed publications: Please run the following chunck only once.
First load the required libraries.

```{r Call Trends}
library(informationRetrieval)
library(RISmed)
library(reshape2)
library(ggplot2)
library(devtools)
library(roxygen2)
YEARs <- 1990:2017
```

First I would like to see if I can get an overall trends of machine-learning in life sciencs.
```{r all-techniques, }
query = '((random forest[tw])  OR (support vector machine[tw]) OR (artificial neural network[tw]) OR (artificial neural networks[tw] OR deep neural networks[tw] or deep learning[tw]) OR (principal component analysis[tw]) OR (hierarchical clustering[tw]) OR (linear regression[tw]) OR (markov model[tw]) OR (decision tree[tw]) OR (TSNE[tw] OR T-SNE[tw] or t-sne[tw] or tsne[tw] or t-SNE[tw] or distributed stochastic neighbor embedding[tw]))'

hpm_all_ml_techs <- get_normliazed_number_of_hits(years=YEARs, query=query, db="pubmed", normalization_value=100)
hpm_all_ml_techs

```

Now plot and fit lines into the points

```{r plt-best-fit-line}
fit_and_plot <- function(hits, years){
   x <- years[1:11]
   y <- hits[1:11]
   plot(y ~ x, xlim=c(1990,2017), ylim=c(0, 1.3), lwd=5, pch=5, xlab=c('Years'), ylab = c('% Publications in Pubmed using a ML technique'),
        cex.axis=1.5, cex.lab=1.5)
   # fit a linear reg
  lm1 <- lm(y ~ x)
  cat("First lm: \n")
  print(lm1)
  x1 <- c(1990, 2000)
  y1 <- predict(lm1, newdata=data.frame(x=x1))
  lines(y1~x1, lwd=3, col='red')
  
  # second part
  x <- years[11:27]
  y <- hits[11:27]
  lm2 <- lm(y~x)
  cat('Second lm: \n')
  print(lm2)
  
  x2 <- c(2000, 2017)
  y2 <- predict(lm2, newdata=data.frame(x=x2))
  points(y ~ x, xlim=c(1990,2017), ylim=c(0, 1.3), lwd=5, pch=4)
  lines(y2 ~ x2, lwd=3, col='red')
} #fit_and_plot#


fit_and_plot(hpm_all_ml_techs, YEARs)


```


Now I will retrive normalized number of hits per machine learning technique. This means that for each, the number of hits for a specific technique is divided to total number papers published in that year. This number is multipled by normalization-value (1000000) to get per million hits.

```{r ML trends}
RF_hits   <- get_normliazed_number_of_hits(years=YEARs, query="random forest[tw]", db="pubmed", normalization_value=1000000)
  
ANN_hits       <-  get_normliazed_number_of_hits(years = YEARs, query="artificial neural network[tw]", db="pubmed", normalization_value=1000000)

NN_term <-  "(artificial neural networks[tw] OR deep neural networks[tw] or deep learning[tw])"
DNN_hits <-  get_normliazed_number_of_hits(years=YEARs, query=NN_term, db="pubmed", normalization_value=1000000)
  
SVM_hits <- get_normliazed_number_of_hits(years=YEARs, query="support vector machine[tw]", db="pubmed", normalization_value=1000000)


PCA_hits <- get_normliazed_number_of_hits(years=YEARs, query="principal component analysis[tw]", db="pubmed", normalization_value=1000000)

HC_hits <- get_normliazed_number_of_hits(years=YEARs, query="hierarchical clustering[tw]", db="pubmed", normalization_value=1000000)

Log_Reg_hits <- get_normliazed_number_of_hits(years=YEARs, query="logistics regression[tw]", db="pubmed", normalization_value=1000000)

Linear_Reg_hits <- get_normliazed_number_of_hits(years=YEARs, query="linear regression[tw]", db="pubmed", normalization_value=1000000)

MM_hits <- get_normliazed_number_of_hits(years=YEARs, query="markov model[tw]", db="pubmed", normalization_value=1000000)


DT_hits <- get_normliazed_number_of_hits(years=YEARs, query="decision tree[tw]", db="pubmed", normalization_value=1000000)

TSNE_term <- "(TSNE[tw] OR T-SNE[tw] or t-sne[tw] or tsne[tw] or t-SNE[tw] or distributed stochastic neighbor embedding[tw])"
TSNE_hits <- get_normliazed_number_of_hits(years=YEARs, query=TSNE_term, db="pubmed", normalization_value=1000000)
```

Now combined the data we reterieved (trends in pulblication over various techniques) and make a data frame as it is simpler to work with (note the 'as.numeric' is to convert from list to numeric ):
```{r combined data}
ML_df <- data.frame(years=YEARs, RF=as.numeric(RF_hits), SVM=as.numeric(SVM_hits), ANN=as.numeric(ANN_hits),                                      PCA=as.numeric(PCA_hits), LRM=as.numeric(Linear_Reg_hits), MM=as.numeric(MM_hits), DT=as.numeric(DT_hits),        HC=as.numeric(HC_hits), DNN=as.numeric(DNN_hits), TSNE=as.numeric(TSNE_hits))

melted_df <- melt(ML_df, id=c("years"))


plt <- ggplot(data=melted_df, aes(x=years, y=value, colour=variable))+ geom_line(size=3)+scale_color_manual(values = c("red", "blue", "green", "brown", "yellow", "orange", "grey", "purple","maroon", "black", "navy")) 
plt + theme(axis.text.x = element_text(size=15, color="black"), axis.title.x=element_text(size=20),  
             axis.text.y = element_text(size=15, color="black"), axis.title.y=element_text(size=20), 
             panel.background = element_rect(fill = 'white', colour = 'black'), plot.title = element_text(size = rel(2)) ) + 
   ggtitle("Machine Learning Trends in Pubmed")+ xlab("years")+ylab("Number of Publications (per million)")
 
```


because number of publications for PCA is far greater than other techinques, it overshadows other techniques. Therefore
we have analysed trends without PCA:
```{r without PCA}
ML_no_PCA_no_LinRM_df <- data.frame(years=YEARs, RF=as.numeric(RF_hits), SVM=as.numeric(SVM_hits), ANN=as.numeric(ANN_hits),    MM=as.numeric(MM_hits), DT=as.numeric(DT_hits), HC=as.numeric(HC_hits), DNN=as.numeric(DNN_hits),TSNE=as.numeric(TSNE_hits))



ML_no_PCA_no_LinRM <- melt(ML_no_PCA_no_LinRM_df, id=c("years"))

plt2 <- ggplot(data=ML_no_PCA_no_LinRM, aes(x=years, y=value, colour=variable))+ geom_line(size=3)+scale_color_manual(values = c("red", "blue", "green",  "orange", "grey", "purple","maroon",  "navy")) 

plt2 + theme(axis.text.x = element_text(size=15, color="black"), axis.title.x=element_text(size=20),  
             axis.text.y = element_text(size=15, color="black"), axis.title.y=element_text(size=20), 
             panel.background = element_rect(fill = 'white', colour = 'black'), plot.title = element_text(size = rel(2))) +
            #legend.justification=c(0,1), legend.position = c(0, 1) ) + 
   ggtitle("Machine Learning Trends in Pubmed")+ xlab("years")+ylab("Number of Publications (per million)")

```





Now I need a zoomed in figure to show that TSNE has a sharp gradient during 2015-2017

```{r TSNE and LRM}
tsne_years <- YEARs[18:28]
tsne_hits  <- as.numeric(TSNE_hits[18:28])

plot(tsne_hits~tsne_years, col='navy', lwd=5, type='b', xlab='year', ylab="Number of Publications (per million)")
tsne
```



```{r LR fit}
plot(as.numeric(Linear_Reg_hits[15:28])~YEARs[15:28], lwd=3, col='red')
LR_fit <- lm(as.numeric(Linear_Reg_hits[15:28])~YEARs[15:28])
LR_fit
abline(LR_fit)

```



We want to limit only on next generation sequencing OR high-throughput sequencing
```{r ML with NGS}
RF_NGS_Q = "(next generation sequencing[tw] OR high-throughput sequencing[tw] or high throughput sequencing[tw]) AND random forest[tw]"
RF_NGS_hits = get.Normalized.Number.Of.Hits(1990:2014, query=RF_NGS_Q, db="pubmed", normalization_value=1000000)

SVM_NGS_Q = "(next generation sequencing[tw] OR high-throughput sequencing[tw] or high throughput sequencing[tw]) AND support vector machine[tw]"
SVM_NGS_hits = get.Normalized.Number.Of.Hits(1990:2014, query=SVM_NGS_Q, db="pubmed", normalization_value=1000000)

ANN_NGS_Q = "(next generation sequencing[tw] OR high-throughput sequencing[tw] or high throughput sequencing[tw]) AND artificial neural networks[tw]"
ANN_NGS_hits = get.Normalized.Number.Of.Hits(1990:2014, query=ANN_NGS_Q, db="pubmed", normalization_value=1000000)

PCA_NGS_Q = "(next generation sequencing[tw] OR high-throughput sequencing[tw] or high throughput sequencing[tw]) AND principal component analysis[tw]"
PCA_NGS_hits = get.Normalized.Number.Of.Hits(1990:2014, query=PCA_NGS_Q, db="pubmed", normalization_value=1000000)


```
